{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import time\r\n",
    "import mediapipe as mp "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Mediapipe Holistic Introduction\r\n",
    "mp_holistic = mp.solutions.holistic\r\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#prediction Function using mediapipe\r\n",
    "def mediapipe_detection(image,model):\r\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\r\n",
    "    image.flags.writeable = False\r\n",
    "    results = model.process(image)\r\n",
    "    image.flags.writeable = True\r\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\r\n",
    "    return image, results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Draw on prediction\r\n",
    "def draw_on_prediction(image,results):\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "        image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS)\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "        image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "        image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "        image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Draw landmark with formatting\r\n",
    "def draw_formatted_landmark(image,results):\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "    image, \r\n",
    "    results.face_landmarks, \r\n",
    "    mp_holistic.FACE_CONNECTIONS,\r\n",
    "    mp_drawing.DrawingSpec(color=(80,120,50), thickness =1, circle_radius=1),\r\n",
    "    mp_drawing.DrawingSpec(color=(90,200,111), thickness =1, circle_radius=1)\r\n",
    "    )\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "    image, \r\n",
    "    results.left_hand_landmarks, \r\n",
    "    mp_holistic.HAND_CONNECTIONS,\r\n",
    "    mp_drawing.DrawingSpec(color=(40,10,210), thickness =2, circle_radius=2),\r\n",
    "    mp_drawing.DrawingSpec(color=(180,96,72), thickness =2, circle_radius=2)\r\n",
    "    )\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "    image, \r\n",
    "    results.right_hand_landmarks, \r\n",
    "    mp_holistic.HAND_CONNECTIONS,\r\n",
    "    mp_drawing.DrawingSpec(color=(40,10,210), thickness =2, circle_radius=2),\r\n",
    "    mp_drawing.DrawingSpec(color=(180,96,72), thickness =2, circle_radius=2)\r\n",
    "    )\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "    image, \r\n",
    "    results.pose_landmarks, \r\n",
    "    mp_holistic.POSE_CONNECTIONS,\r\n",
    "    mp_drawing.DrawingSpec(color=(130,140,10), thickness =2, circle_radius=2),\r\n",
    "    mp_drawing.DrawingSpec(color=(80,36,14), thickness =2, circle_radius=2)\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "cap = cv2.VideoCapture(0)\r\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\r\n",
    "    while cap.isOpened():\r\n",
    "\r\n",
    "        #read feed\r\n",
    "        ret, frame = cap.read()\r\n",
    "\r\n",
    "        # Make prediction\r\n",
    "        image, results = mediapipe_detection(frame, holistic)\r\n",
    "\r\n",
    "        # Draw Connections\r\n",
    "        # draw_on_prediction(image,results)\r\n",
    "\r\n",
    "        # Draw formatted Landmark\r\n",
    "        draw_formatted_landmark(image,results)\r\n",
    "\r\n",
    "        #print(results)\r\n",
    "        cv2.imshow(\"'Holistic feed\", image)\r\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\r\n",
    "            break\r\n",
    "    cap.release()\r\n",
    "    cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# Flattening Array \r\n",
    "def keypoint_ext(results, landmark=\"pose\"):    \r\n",
    "    fin_arr = np.array([])\r\n",
    "    if landmark.lower() == \"pose\":\r\n",
    "        for res in results.pose_landmarks.landmark:\r\n",
    "            fin_arr = np.append(fin_arr, [res.x,res.y,res.z]).flatten()\r\n",
    "\r\n",
    "        return fin_arr\r\n",
    "\r\n",
    "    if landmark.lower() == \"face\":\r\n",
    "        for res in results.face_landmarks.landmark:\r\n",
    "            fin_arr = np.append(fin_arr, [res.x,res.y,res.z]).flatten()\r\n",
    "\r\n",
    "        return fin_arr\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "pose_arr = keypoint_ext(results, \"pose\")\r\n",
    "print(type(pose_arr))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "fin_arr.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfa321ceadaff8ede680e18b6c39b81c6d4f3f238bfd124ccbdfb384e71e26c9"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}